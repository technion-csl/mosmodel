diff --git a/analysis/assessPolynomialModels.py b/analysis/assessPolynomialModels.py
index 1e2c8f8..468ec3b 100755
--- a/analysis/assessPolynomialModels.py
+++ b/analysis/assessPolynomialModels.py
@@ -21,7 +21,10 @@ df = pd.read_csv(args.input_file, index_col='layout')
 x = df[[args.x_metric]]
 y = df[args.metric]
 
+import matplotlib
 import matplotlib.pyplot as plt
+matplotlib.use('Agg') #use a non-interactive backend
+
 fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(4,3))
 ax.scatter(x, y, marker='o', s=10, label='measurements')
 
diff --git a/analysis/common.mk b/analysis/common.mk
index 66702ff..d966534 100644
--- a/analysis/common.mk
+++ b/analysis/common.mk
@@ -4,31 +4,31 @@ $(MODULE_NAME)/%: EXPERIMENTS_ROOT := $(EXPERIMENTS_ROOT)
 ANALYSIS_DIRS := $(MODULE_NAME)
 NORMALIZED_SCATTER_FILE := $(ANALYSIS_DIRS)/normalized_scatter.csv
 SCATTER_FILE := $(ANALYSIS_DIRS)/scatter.csv
+MEDIAN_SCATTER_FILE := $(ANALYSIS_DIRS)/median_scatter.csv
 WHISKER_FILE := $(ANALYSIS_DIRS)/whisker.csv
 ALL_REPEATS_SCATTER_FILE := $(ANALYSIS_DIRS)/all_repeats_scatter.csv
 NORMALIZED_SCATTER_CHART := $(ANALYSIS_DIRS)/normalized_scatter.pdf
 SCATTER_CHART := $(ANALYSIS_DIRS)/scatter.pdf
+MEDIAN_SCATTER_CHART := $(ANALYSIS_DIRS)/median_scatter.pdf
 WHISKER_CHART := $(ANALYSIS_DIRS)/whisker.pdf
 ALL_REPEATS_CHART := $(ANALYSIS_DIRS)/all_repeats.pdf
-POLY_CHART := $(ANALYSIS_DIRS)/poly.pdf
 
-ALL_CHARTS := $(SCATTER_CHART) $(WHISKER_CHART) $(ALL_REPEATS_CHART) $(POLY_CHART)
-ALL_CSVS := $(NORMALIZED_SCATTER_FILE) $(SCATTER_FILE) $(WHISKER_FILE) $(ALL_REPEATS_SCATTER_FILE)
+ALL_CHARTS := $(SCATTER_CHART) $(MEDIAN_SCATTER_CHART) $(WHISKER_CHART) $(ALL_REPEATS_CHART)
+ALL_CSVS := $(NORMALIZED_SCATTER_FILE) $(SCATTER_FILE) $(MEDIAN_SCATTER_FILE) $(WHISKER_FILE) $(ALL_REPEATS_SCATTER_FILE)
 
 $(MODULE_NAME)%: ALL_CSVS := $(ALL_CSVS) 
 $(MODULE_NAME)%: ALL_CHARTS := $(ALL_CHARTS)
 $(MODULE_NAME): $(ALL_CSVS) $(ALL_CHARTS)
 
-$(POLY_CHART): $(SCATTER_FILE)
-	$(POLY_PLOT) --metric='cpu-cycles' \
-		--input_file=$< --output_file=$@ > $(dir $@)/poly.csv
-
 $(NORMALIZED_SCATTER_CHART): $(NORMALIZED_SCATTER_FILE)
 	gnuplot -e "input_file='$<'" -e "output_file='$@'" $(SCATTER_PLOT)
 
 $(SCATTER_CHART): $(SCATTER_FILE)
 	gnuplot -e "input_file='$<'" -e "output_file='$@'" $(SCATTER_PLOT)
 
+$(MEDIAN_SCATTER_CHART): $(MEDIAN_SCATTER_FILE)
+	gnuplot -e "input_file='$<'" -e "output_file='$@'" $(SCATTER_PLOT)
+
 $(ALL_REPEATS_CHART): $(ALL_REPEATS_SCATTER_FILE)
 	if [[ $(NUM_OF_REPEATS) != 1 ]]; then
 	gnuplot -e "input_file='$<'" -e "output_file='$@'" $(SCATTER_PLOT)
@@ -44,6 +44,11 @@ $(NORMALIZED_SCATTER_FILE): analysis/%/normalized_scatter.csv: results/%/mean.cs
 	$(ARRANGE_DATA_TO_PLOT) --normalize='by-y' --y-metric='cpu-cycles' \
 		--mean_file=$< --output=$@
 
+$(MEDIAN_SCATTER_FILE): analysis/%/median_scatter.csv: results/%/median.csv
+	mkdir -p $(dir $@)
+	$(ARRANGE_DATA_TO_PLOT) --y-metric='cpu-cycles' \
+		--mean_file=$< --output=$@
+
 $(SCATTER_FILE): analysis/%/scatter.csv: results/%/mean.csv
 	mkdir -p $(dir $@)
 	$(ARRANGE_DATA_TO_PLOT) --y-metric='cpu-cycles' \
diff --git a/analysis/module.mk b/analysis/module.mk
index 2d33b1f..7ebfa49 100644
--- a/analysis/module.mk
+++ b/analysis/module.mk
@@ -1,12 +1,21 @@
 MODULE_NAME := analysis
 SUBMODULES := \
+	single_page_size \
 	growing_window_2m \
 	random_window_2m \
 	sliding_window \
 	linear_models_coeffs \
 	pebs_tlb_miss_trace \
+	fixed_selector \
+	genetic_selector \
+	moselect \
+	bayesian_optimization \
+	mosrange \
 	mosmodel \
-	all_data
+	all_data \
+	manual_layouts \
+	vanilla
+
 SUBMODULES := $(addprefix $(MODULE_NAME)/,$(SUBMODULES))
 
 ARRANGE_DATA_TO_PLOT := $(MODULE_NAME)/arrangeDataToPlot.py
diff --git a/analysis/mosmodel/module.mk b/analysis/mosmodel/module.mk
index 40cd2e5..3432ef0 100644
--- a/analysis/mosmodel/module.mk
+++ b/analysis/mosmodel/module.mk
@@ -28,8 +28,8 @@ MOSMODEL_TEST_MEAN_CSV_FILE := $(MODULE_NAME)/test/mean.csv
 $(MODULE_NAME): $(MAX_ERRORS_PLOTS) $(TRAIN_ERRORS_FILE) $(TEST_ERRORS_FILE) \
 	$(TEST_AVG_ERRORS) $(CROSS_VALIDATION_FILE)
 
-$(MAX_ERRORS_PLOTS): $(TRAIN_ERRORS_FILE)
-	$(PLOT_MAX_ERRORS) --errors=$(TRAIN_ERRORS_FILE) --plot_title=$(MAX_ERRORS_PLOT_TITLE) --output=$(@D)
+$(MAX_ERRORS_PLOTS): $(TEST_ERRORS_FILE)
+	$(PLOT_MAX_ERRORS) --errors=$(TEST_ERRORS_FILE) --plot_title=$(MAX_ERRORS_PLOT_TITLE) --output=$(@D)
 
 $(POLY_COEFFICIENTS):
 	$(COLLECT_POLYNOMIAL_COEFFICIENTS) --output=$@
diff --git a/analysis/mosmodel/plotMaxErrors.py b/analysis/mosmodel/plotMaxErrors.py
index 064d8a8..4b74812 100755
--- a/analysis/mosmodel/plotMaxErrors.py
+++ b/analysis/mosmodel/plotMaxErrors.py
@@ -5,6 +5,7 @@ def round_up(num, to_nearest_num):
     return math.ceil((num / to_nearest_num)) * to_nearest_num
 
 import matplotlib
+matplotlib.use('Agg') #use a non-interactive backend
 import matplotlib.pyplot as plt
 import numpy as np
 
@@ -13,7 +14,8 @@ def plotModels(df, models, output):
     max_errors_df = pd.DataFrame(columns=['model', 'max-error'])
     for m in models:
         max_error = df[m + error_suffix].abs().max() * 100
-        max_errors_df = max_errors_df.append({'model': m, 'max-error': max_error}, ignore_index=True)
+        new_row = pd.Series({'model': m, 'max-error': max_error})
+        max_errors_df = pd.concat([max_errors_df, new_row.to_frame().T], ignore_index=True)
 
     csv_output = output.replace('.pdf', '.csv')
     if csv_output == output:
diff --git a/analysis/pebs_tlb_miss_trace/binAddresses.py b/analysis/pebs_tlb_miss_trace/binAddresses.py
index db12359..c6f125d 100755
--- a/analysis/pebs_tlb_miss_trace/binAddresses.py
+++ b/analysis/pebs_tlb_miss_trace/binAddresses.py
@@ -29,6 +29,20 @@ def applyBins(df, pid, tid, bin_width,
     df.loc[file_mask, 'ADDR'] /= bin_width
     df.loc[file_mask, 'PAGE_TYPE'] = 'file'
 
+def normalizePebsAccesses(pebs_df):
+    # filter and eep only brk pool accesses
+    pebs_df = pebs_df[pebs_df['PAGE_TYPE'].str.contains('brk')]
+    if pebs_df.empty:
+        sys.exit('Input file does not contain page accesses information about the brk pool!')
+    pebs_df = pebs_df[['PAGE_NUMBER', 'NUM_ACCESSES']]
+    pebs_df = pebs_df.reset_index()
+
+    # transform NUM_ACCESSES from absolute number to percentage
+    total_access = pebs_df['NUM_ACCESSES'].sum()
+    pebs_df['TLB_COVERAGE'] = pebs_df['NUM_ACCESSES'].mul(100).divide(total_access)
+    pebs_df = pebs_df.sort_values('TLB_COVERAGE', ascending=False)
+    return pebs_df
+
 import argparse
 import sys
 import math
@@ -77,3 +91,7 @@ df_g=df_g.groupby(['PAGE_NUMBER', 'PAGE_TYPE'], sort=False).sum().reset_index()
 df_g.sort_values('NUM_ACCESSES', ascending=False, inplace=True)
 #Write all processes data to single file
 writeDataframeToCsv(df_g, args.output_file)
+
+df=normalizePebsAccesses(df_g)
+writeDataframeToCsv(df, args.output_file+'.normalized')
+
diff --git a/analysis/pebs_tlb_miss_trace/findWeightedWindow.py b/analysis/pebs_tlb_miss_trace/findWeightedWindow.py
index 60aa95f..e8ca404 100755
--- a/analysis/pebs_tlb_miss_trace/findWeightedWindow.py
+++ b/analysis/pebs_tlb_miss_trace/findWeightedWindow.py
@@ -60,7 +60,7 @@ def findWeightedWindow(weight):
     max_access_end_page = 1
     weighted_accesses = math.floor(total_access * weight)
     max_sum = 0
-    while l <= r:
+    while l < r:
         mid = math.floor((l+r)/2)
         l_sum = sumAccesses(l, mid)
         r_sum = sumAccesses(mid+1, r)
@@ -68,12 +68,12 @@ def findWeightedWindow(weight):
             #weight, l_sum, r_sum, weighted_accesses, l,r,mid))
         if l_sum <  weighted_accesses and r_sum < weighted_accesses:
             break
-        if l_sum > weighted_accesses and l_sum > r_sum:
+        if l_sum >= weighted_accesses and l_sum > r_sum:
             max_access_start_page = l
             max_access_end_page = mid
             r = mid
             max_sum = l_sum
-        elif r_sum > weighted_accesses:
+        elif r_sum >= weighted_accesses:
             max_access_start_page = mid+1
             max_access_end_page = r
             l = mid+1
@@ -103,7 +103,7 @@ def findWeightedWindow(weight):
     #print(str.format('[DEBUG] [3]: weight = {0} , left = {1} , right = {2}', weight, l, r))
     max_access_start_page = l
     max_access_end_page = r
-    left_weight = sumAccesses(0, l) / total_access
+    left_weight = sumAccesses(0, l-1) / total_access
     right_weight = sumAccesses(r+1, actual_total_pages-1) / total_access
     left_weight = int(left_weight * 100)
     right_weight = int(right_weight * 100)
diff --git a/analysis/pebs_tlb_miss_trace/module.mk b/analysis/pebs_tlb_miss_trace/module.mk
index 747785d..254036e 100644
--- a/analysis/pebs_tlb_miss_trace/module.mk
+++ b/analysis/pebs_tlb_miss_trace/module.mk
@@ -6,6 +6,7 @@ SUBMODULES := $(addprefix $(MODULE_NAME)/,$(SUBMODULES))
 COUNT_MEMORY_ACCESSES := $(MODULE_NAME)/countMemoryAccesses.py
 PARSE_PERF_MEM_RAW_FILE := $(MODULE_NAME)/parsePerfMem.py
 BIN_ADDRESSES := $(MODULE_NAME)/binAddresses.py
+CALCULATE_PAGES_WEIGHTS := $(MODULE_NAME)/calculatePagesWeights.py
 PLOT_BINS := $(MODULE_NAME)/plotBins.py
 FIND_WINDOW := $(MODULE_NAME)/findWeightedWindow.py
 
@@ -19,6 +20,7 @@ WINDOW_4KB_FILE := $(MODULE_NAME)/hot_region_4kb.txt
 MEM_ACCESSES_FILE := $(MODULE_NAME)/mem_accesses.csv
 MEM_ACCESS_COUNT_FILE := $(MODULE_NAME)/mem_access_count.csv
 MEM_BINS_2MB_CSV_FILE := $(MODULE_NAME)/mem_bins_2mb.csv
+MEM_BINS_2MB_BRK_RATIO_CSV_FILE := $(MODULE_NAME)/mem_bins_2mb_brk.csv
 MEM_BINS_2MB_CHART_FILE := $(MODULE_NAME)/mem_bins_2mb.pdf
 MEM_BINS_4KB_CSV_FILE := $(MODULE_NAME)/mem_bins_4kb.csv
 
@@ -34,7 +36,7 @@ $(WINDOW_2MB_FILE): $(MEMORY_FOOTPRINT_FILE) $(MEM_BINS_2MB_CSV_FILE)
 	mem_footprint=$(shell tail -n1 $< | cut -d ',' -f 4)
 	$(FIND_WINDOW) --input_file=$(MEM_BINS_2MB_CSV_FILE) --output_file=$@ --memory_footprint=$$mem_footprint --page_size=2MB
 
-$(WINDOW_4KB_FILE): $(MEMORY_FOOTPRINT_FILE) $(MEM_BINS_4KB_CSV_FILE)
+$(WINDOW_4KB_FILE): $(MEMORY_FOOTPRINT_FILE) |$(MEM_BINS_4KB_CSV_FILE)
 	mem_footprint=$(shell tail -n1 $< | cut -d ',' -f 4)
 	$(FIND_WINDOW) --input_file=$(MEM_BINS_4KB_CSV_FILE) --output_file=$@ --memory_footprint=$$mem_footprint --page_size=4KB
 
@@ -43,28 +45,40 @@ $(MEM_BINS_2MB_CHART_FILE): $(MEM_BINS_2MB_CSV_FILE)
 		--figure_y_label="tlb misses" --time_windows=1
 
 $(MEM_BINS_4KB_CSV_FILE): $(PEBS_EXP_OUT_DIR)
-	$(PERF_MEM_REPORT_PREFIX) -i $^/perf.data report | \
+	{ $(PERF_MEM_REPORT_PREFIX) -i $^/perf.data report | \
 		$(FIX_DELIM_IN_PERF_MEM_OUTPUT_HEADER) | \
 		$(BIN_ADDRESSES) --width=4096 --output=$@ \
-		--pools_range_file=$^/pools_base_pointers.out
+		--pools_range_file=$^/pools_base_pointers.out ;} >> $(dir $@)/analyze.log 2>&1
 
-$(MEM_BINS_2MB_CSV_FILE): $(PEBS_EXP_OUT_DIR)
-	$(PERF_MEM_REPORT_PREFIX) -i $^/perf.data report | \
+$(MEM_BINS_2MB_BRK_RATIO_CSV_FILE): $(MEM_BINS_2MB_CSV_FILE)
+	$(CALCULATE_PAGES_WEIGHTS) --type brk --input $< --output $@
+
+$(MEM_BINS_2MB_CSV_FILE): $(PEBS_EXP_OUT_DIR) 
+	{ $(PERF_MEM_REPORT_PREFIX) -i $^/perf.data report | \
 		$(FIX_DELIM_IN_PERF_MEM_OUTPUT_HEADER) | \
 		$(BIN_ADDRESSES) --width=$$(( 2**21 )) --output=$@ \
-		--pools_range_file=$^/pools_base_pointers.out
+		--pools_range_file=$^/pools_base_pointers.out ;} >> $(dir $@)/analyze.log 2>&1
+	echo "deleting the content of the perf.data file to save storage: $^/perf.data"
+	cat /dev/null > $^/perf.data
+	echo "-----------------------------------------"
+	echo "analyze.log content:"
+	cat $(dir $@)/analyze.log
+	echo "-----------------------------------------"
+	# if [[ $$ASSERT_PEBS_SAMPLES_NOT_LOST == 1 ]]; then \
+	# 	! grep -q "samples and lost" $(dir $@)/analyze.log; \
+	# fi;
 
 $(MEM_ACCESS_COUNT_FILE): $(PEBS_EXP_OUT_DIR)
-	$(PERF_MEM_REPORT_PREFIX) -i $^/perf.data report | \
+	{ $(PERF_MEM_REPORT_PREFIX) -i $^/perf.data report | \
 		$(FIX_DELIM_IN_PERF_MEM_OUTPUT_HEADER) | \
-		$(COUNT_MEMORY_ACCESSES) -o $@ -p $^/pools_base_pointers.out
+		$(COUNT_MEMORY_ACCESSES) -o $@ -p $^/pools_base_pointers.out ;} >> $(dir $@)/analyze.log 2>&1
 
 $(MEM_ACCESSES_FILE): $(PEBS_EXP_OUT_DIR)
-	$(PERF_MEM_REPORT_PREFIX) -i $^/perf.data report | \
+	{ $(PERF_MEM_REPORT_PREFIX) -i $^/perf.data report | \
 		$(FIX_DELIM_IN_PERF_MEM_OUTPUT_HEADER) | \
-		$(PARSE_PERF_MEM_RAW_FILE) -o $@ -p $^/pools_base_pointers.out
+		$(PARSE_PERF_MEM_RAW_FILE) -o $@ -p $^/pools_base_pointers.out ;} >> $(dir $@)/analyze.log 2>&1
 
 $(MODULE_NAME)/clean:
 	rm -rf $(PEBS_TARGET_FILES)
-	cd $(dir $@) && rm -f *csv*
+	cd $(dir $@) && rm -f *csv* && rm -f analyze.log
 
diff --git a/analysis/performance_statistics.py b/analysis/performance_statistics.py
index 39f11a4..ca0353a 100755
--- a/analysis/performance_statistics.py
+++ b/analysis/performance_statistics.py
@@ -4,8 +4,13 @@ import pandas as pd
 import numpy as np
 
 class PerformanceStatistics:
-    def __init__(self, csv_file, index_col=None):
-        self._df = pd.read_csv(csv_file, index_col=index_col)
+    def __init__(self, perf_file, index_col=None):
+        if type(perf_file) is str:
+            self._df = pd.read_csv(perf_file, index_col=index_col)
+        elif type(perf_file) is pd.DataFrame:
+            self._df = perf_file.copy()
+        else:
+            assert False
         self._df.fillna(0, inplace=True)
 
     def __getDataSet(self, index=None):
@@ -27,6 +32,12 @@ class PerformanceStatistics:
     def getIndexColumn(self):
         return np.array(self._df.index)
 
+    def getWalkPending(self, index=None):
+        return self.__getWalkCounter(index, 'pending')
+
+    def getWalkActive(self, index=None):
+        return self.__getWalkCounter(index, 'active')
+
     def getWalkDuration(self, index=None):
         walk_duration = self.__getWalkCounter(index, 'active')
         if walk_duration is not None:
@@ -46,6 +57,9 @@ class PerformanceStatistics:
             raise Exception('the data-set has no performance counters for STLB hits!')
 
     def getStlbMisses(self, index=None):
+        return self.getStlbMisses_completed(index)
+
+    def getStlbMisses_started(self, index=None):
         data_set = self.__getDataSet(index)
         if 'dtlb_load_misses.miss_causes_a_walk' in self._df.columns \
                 and 'dtlb_store_misses.miss_causes_a_walk' in self._df.columns:
@@ -54,8 +68,7 @@ class PerformanceStatistics:
         else:
             raise Exception('the data-set has no performance counters for TLB misses!')
 
-    '''
-    def getStlbMisses(self, index=None):
+    def getStlbMisses_completed(self, index=None):
         data_set = self.__getDataSet(index)
         if 'dtlb_load_misses.walk_completed' in self._df.columns \
         and 'dtlb_store_misses.walk_completed' in self._df.columns:
@@ -63,9 +76,8 @@ class PerformanceStatistics:
                     + data_set['dtlb_store_misses.walk_completed']
         else:
             raise Exception('the data-set has no performance counters for STLB misses (dtlb-misses-walk-completed)!')
-    '''
 
-    def getStlbMisses2m(self, index=None):
+    def getStlbMisses2m_completed(self, index=None):
         data_set = self.__getDataSet(index)
         if 'dtlb_load_misses.walk_completed_2m_4m' in self._df.columns \
         and 'dtlb_store_misses.walk_completed_2m_4m' in self._df.columns:
@@ -75,7 +87,7 @@ class PerformanceStatistics:
             return self.getStlbMisses(index)
             #raise Exception('the data-set has no performance counters for STLB misses (for 2MB pages)!')
 
-    def getStlbMisses4k(self, index=None):
+    def getStlbMisses4k_completed(self, index=None):
         data_set = self.__getDataSet(index)
         if 'dtlb_load_misses.walk_completed_4k' in self._df.columns \
         and 'dtlb_store_misses.walk_completed_4k' in self._df.columns:
@@ -188,5 +200,13 @@ class PerformanceStatistics:
             raise Exception('the data-set has no performance counters for CPU cycles!')
         return 0
 
+    def getRefCycles(self, index=None):
+        data_set = self.__getDataSet(index)
+        if self._df.columns.contains('ref-cycles'):
+            return data_set['ref-cycles']
+        else:
+            raise Exception('the data-set has no performance counters for ref cycles!')
+        return 0
+
     def getDataFrame(self):
         return self._df.copy()
diff --git a/benchmark.mk b/benchmark.mk
index 9814e8f..0e97e38 100644
--- a/benchmark.mk
+++ b/benchmark.mk
@@ -1,2 +1,5 @@
 BENCHMARK_PATH ?= $(ROOT_DIR)/toy_benchmark
+PRE_RUN_SCRIPT_NAME ?= ./pre_run.sh
+POST_RUN_SCRIPT_NAME ?= ./post_run.sh
+
 
diff --git a/experiments/growing_window_2m/module.mk b/experiments/growing_window_2m/module.mk
index 65e2235..ee51093 100644
--- a/experiments/growing_window_2m/module.mk
+++ b/experiments/growing_window_2m/module.mk
@@ -3,9 +3,9 @@ MODULE_NAME := experiments/growing_window_2m
 include $(EXPERIMENTS_TEMPLATE)
 
 CREATE_GROWING_WINDOW_LAYOUTS := $(MODULE_NAME)/createLayouts.py
-$(LAYOUTS_FILE): $(MEMORY_FOOTPRINT_FILE)
+$(LAYOUT_FILES): $(MEMORY_FOOTPRINT_FILE)
 	$(CREATE_GROWING_WINDOW_LAYOUTS) \
 		--memory_footprint=$(MEMORY_FOOTPRINT_FILE) --num_layouts=$(NUM_LAYOUTS) \
-		--output=$@
+		--output=$(dir $@)/..
 
 
diff --git a/experiments/layouts_generator.py b/experiments/layouts_generator.py
index 07b78ac..09e2414 100755
--- a/experiments/layouts_generator.py
+++ b/experiments/layouts_generator.py
@@ -6,6 +6,8 @@ import pandas as pd
 import numpy as np
 import random
 import math
+from Utils.utils import *
+from Utils.ConfigurationFile import *
 
 kb = 1024
 mb = 1024*kb
@@ -33,8 +35,11 @@ class LayoutsGenerator:
         self._brk_2mb_footprint = round_up(self._brk_footprint, 2*mb)
         self._mmap_1gb_footprint = round_up(self._mmap_footprint, gb)
         self._brk_1gb_footprint = round_up(self._brk_footprint, gb)
+        self._mmap_pool_size = self._mmap_footprint
+        self._brk_pool_size = self._brk_footprint
 
-    def addLayout(self,
+
+    def addSingleWindowLayout(self,
             brk_start_2m=0, brk_end_2m=0,
             mmap_start_2m=0, mmap_end_2m=0,
             brk_start_1g=0, brk_end_1g=0,
@@ -42,15 +47,38 @@ class LayoutsGenerator:
             add_to_front=False):
         brk_footprint = max(brk_end_2m, brk_end_1g, self._brk_footprint)
         mmap_footprint = max(mmap_end_2m, mmap_end_1g, self._mmap_footprint)
-        layout = '--file_pool_size 1GB --anon_pool_size {aps} --anon_start_2mb {as2} --anon_end_2mb {ae2} --anon_start_1gb {as1} --anon_end_1gb {ae1} --brk_pool_size {bps} --brk_start_2mb {bs2} --brk_end_2mb {be2} --brk_start_1gb {bs1} --brk_end_1gb {be1}'.format(
-                aps=mmap_footprint, as2=mmap_start_2m, ae2=mmap_end_2m,
-                as1=mmap_start_1g, ae1=mmap_end_1g,
-                bps=brk_footprint, bs2=brk_start_2m, be2=brk_end_2m,
-                bs1=brk_start_1g, be1=brk_end_1g)
+        self._mmap_pool_size = max(mmap_footprint, self._mmap_pool_size)
+        self._brk_pool_size = max(brk_footprint, self._brk_pool_size)
+        configuration = Configuration()
+        if brk_start_2m != brk_end_2m:
+            configuration.addWindow(
+                    type=configuration.TYPE_BRK,
+                    page_size=Configuration.HUGE_2MB_PAGE_SIZE,
+                    start_offset=brk_start_2m,
+                    end_offset=brk_end_2m)
+        if brk_start_1g != brk_end_1g:
+            configuration.addWindow(
+                    type=configuration.TYPE_BRK,
+                    page_size=Configuration.HUGE_1GB_PAGE_SIZE,
+                    start_offset=brk_start_1g,
+                    end_offset=brk_end_1g)
+        if mmap_start_2m != mmap_end_2m:
+            configuration.addWindow(
+                    type=configuration.TYPE_MMAP,
+                    page_size=Configuration.HUGE_2MB_PAGE_SIZE,
+                    start_offset=mmap_start_2m,
+                    end_offset=mmap_end_2m)
+        if mmap_start_1g != mmap_end_1g:
+            configuration.addWindow(
+                    type=configuration.TYPE_MMAP,
+                    page_size=Configuration.HUGE_1GB_PAGE_SIZE,
+                    start_offset=mmap_start_1g,
+                    end_offset=mmap_end_1g)
+
         if add_to_front:
-            self._layouts.insert(0, layout)
+            self._layouts.insert(0, configuration)
         else:
-            self._layouts.append(layout)
+            self._layouts.append(configuration)
 
     def buildGrowingWindowLayouts(self, max_1gb_hugepages):
         step = int(math.floor(self._brk_footprint / (self._num_layouts-1)))
@@ -73,7 +101,7 @@ class LayoutsGenerator:
             # reverse layouts list order to enforce running layouts with more
             # huge pages first in growing_window to prevent huge-pages-reservation failures
             # in case of memory fragmentation (and then huge-pages reservation fails)
-            self.addLayout(
+            self.addSingleWindowLayout(
                     brk_start_2m=layout_start_2m, brk_end_2m=layout_end_2m,
                     mmap_start_2m=0, mmap_end_2m=self._mmap_2mb_footprint,
                     brk_start_1g=0, brk_end_1g=end_1g,
@@ -93,7 +121,7 @@ class LayoutsGenerator:
             brk_end_2mb = self._brk_2mb_footprint
             brk_end_1gb = 0
 
-        self.addLayout(
+        self.addSingleWindowLayout(
                 brk_start_2m=brk_start_2mb, brk_end_2m=brk_end_2mb,
                 mmap_start_2m=0, mmap_end_2m=self._mmap_2mb_footprint,
                 brk_start_1g=0, brk_end_1g=brk_end_1gb,
@@ -112,7 +140,7 @@ class LayoutsGenerator:
             random_end_offset = random.randrange(random_start_offset + window_min_size,
                     end_offset, 2*mb)
 
-            self.addLayout(brk_start_2m=random_start_offset, brk_end_2m=random_end_offset)
+            self.addSingleWindowLayout(brk_start_2m=random_start_offset, brk_end_2m=random_end_offset)
 
     def buildSlidingWindowLayouts(self, hot_region_start, hot_region_length):
         standard_page_size = 4*kb
@@ -154,16 +182,19 @@ class LayoutsGenerator:
             page_size = 2*mb
             if self._use_1gb_pages:
                 end_offset = round_up(end_offset, gb)
-                self.addLayout(brk_start_1g=start_offset, brk_end_1g=end_offset)
+                self.addSingleWindowLayout(brk_start_1g=start_offset, brk_end_1g=end_offset)
             else:
-                self.addLayout(brk_start_2m=start_offset, brk_end_2m=end_offset)
+                self.addSingleWindowLayout(brk_start_2m=start_offset, brk_end_2m=end_offset)
             start_offset += step_size
 
     def exportLayouts(self, output):
         i=1
-        with open(output, 'w+') as output_fid:
-            for l in self._layouts:
-                print('layout{i}: {l}'.format(i=i, l=l), file=output_fid)
-                i += 1
+        for l in self._layouts:
+            l.setPoolsSize(
+                    brk_size=self._brk_pool_size,
+                    file_size=1*gb,
+                    mmap_size=self._mmap_pool_size)
+            l.exportToCSV(output, 'layout' + str(i))
+            i += 1
 
 
diff --git a/experiments/memory_footprint/createLayouts.py b/experiments/memory_footprint/createLayouts.py
index 4f9f246..d1208a7 100755
--- a/experiments/memory_footprint/createLayouts.py
+++ b/experiments/memory_footprint/createLayouts.py
@@ -1,4 +1,9 @@
 #!/usr/bin/env python3
+import sys
+import os
+sys.path.append(os.path.dirname(sys.argv[0])+"/..")
+from Utils.utils import *
+from Utils.ConfigurationFile import *
 
 import argparse
 parser = argparse.ArgumentParser()
@@ -17,13 +22,11 @@ def round_down(x, base):
 mem_max_size = args.mem_max_size_kb * 1024
 brk_pool_size = round_down(mem_max_size, 4096)
 mmap_pool_size = brk_pool_size
-layout_template = '-fps 1GB -aps {0} -as1 {1} -ae1 {2} -as2 {3} -ae2 {4} -bps {5} -bs1 {6} -be1 {7} -bs2 {8} -be2 {9}'
-layout_4kb_pages = str.format(layout_template,
-        mmap_pool_size, 0, 0, 0, 0,
-        brk_pool_size, 0, 0, 0, 0)
 
-layout = 'layout4kb: ' + layout_4kb_pages
 
-with open(args.output, 'w+') as output_fid:
-    print(layout, file=output_fid)
+configuration = Configuration()
+configuration.setPoolsSize(brk_size=brk_pool_size,
+                           file_size=1*gb,
+                           mmap_size=mmap_pool_size)
+configuration.exportToCSV(args.output, "layout4kb")
 
diff --git a/experiments/memory_footprint/module.mk b/experiments/memory_footprint/module.mk
index 7560787..a936622 100644
--- a/experiments/memory_footprint/module.mk
+++ b/experiments/memory_footprint/module.mk
@@ -7,9 +7,10 @@ NUM_OF_REPEATS := 1
 include $(EXPERIMENTS_TEMPLATE)
 
 CREATE_MEMORY_FOOTPRINT_LAYOUTS := $(MODULE_NAME)/createLayouts.py
-$(LAYOUTS_FILE):
+$(LAYOUT_FILES):
 	ram_size_kb=$(shell grep MemTotal /proc/meminfo | cut -d ':' -f 2 | sed 's, ,,g' | sed 's,kB,,g')
-	$(CREATE_MEMORY_FOOTPRINT_LAYOUTS) --mem_max_size_kb=$$ram_size_kb --output=$@
+	$(CREATE_MEMORY_FOOTPRINT_LAYOUTS) --mem_max_size_kb=$$ram_size_kb \
+		--output=$(dir $@)/..
 
 # undefine LAYOUTS to allow next makefiles to use the defaults LAYOUTS
 undefine EXTRA_ARGS_FOR_MOSALLOC
diff --git a/experiments/module.mk b/experiments/module.mk
index d87ce75..803adda 100644
--- a/experiments/module.mk
+++ b/experiments/module.mk
@@ -3,10 +3,20 @@ SUBMODULES := \
 	memory_footprint \
 	single_page_size \
 	pebs_tlb_miss_trace \
+	fixed_selector \
+	genetic_selector \
+	moselect \
+	bayesian_optimization \
+	mosrange \
 	growing_window_2m \
 	random_window_2m \
-	sliding_window
-SUBMODULES := $(addprefix $(MODULE_NAME)/,$(SUBMODULES))
+	sliding_window \
+	manual_layouts \
+	vanilla
+
+EXPERIMENTS_MODULE_NAME := $(MODULE_NAME)
+EXPERIMENTS_SUBMODULES := $(addprefix $(EXPERIMENTS_MODULE_NAME)/,$(SUBMODULES))
+SUBMODULES := $(EXPERIMENTS_SUBMODULES)
 
 ##### mosalloc paths
 RUN_MOSALLOC_TOOL := $(ROOT_DIR)/mosalloc/runMosalloc.py
@@ -18,38 +28,63 @@ export MOSALLOC_TOOL := $(ROOT_DIR)/mosalloc/src/libmosalloc.so
 
 COLLECT_RESULTS := $(SCRIPTS_ROOT_DIR)/collectResults.py
 CHECK_PARANOID := $(SCRIPTS_ROOT_DIR)/checkParanoid.sh
+CHECK_ISOLATION := $(SCRIPTS_ROOT_DIR)/check_isolated_cpus.sh
+CSET_SHIELD_CPUS_SCRIPT := $(SCRIPTS_ROOT_DIR)/cset_shield_node_cpus.sh
+SET_CPU_MAX_PERF := $(SCRIPTS_ROOT_DIR)/set_cpu_max_perf.sh
 SET_THP := $(SCRIPTS_ROOT_DIR)/setTransparentHugePages.sh
 SET_CPU_MEMORY_AFFINITY := $(SCRIPTS_ROOT_DIR)/setCpuMemoryAffinity.sh
 MEASURE_GENERAL_METRICS := $(SCRIPTS_ROOT_DIR)/measureGeneralMetrics.sh
-RUN_BENCHMARK := $(SCRIPTS_ROOT_DIR)/runBenchmark.py
+RUN_BENCHMARK := $(SCRIPTS_ROOT_DIR)/benchmarkRunner.py
+RUN_BENCHMARK_WITH_SLURM := $(SCRIPTS_ROOT_DIR)/runBenchmarkWithSlurm.py
+RUN_WITH_CONDA := $(SCRIPTS_ROOT_DIR)/run_with_conda.sh
 COLLECT_MEMORY_FOOTPRINT := $(SCRIPTS_ROOT_DIR)/collectMemoryFootprint.py
+CREATE_PERF_COMMAND := $(SCRIPTS_ROOT_DIR)/build_perf_command.sh
+export PERF_COMMAND := $(SCRIPTS_ROOT_DIR)/perf_command.txt
 
 ###### global constants
 
 export EXPERIMENTS_ROOT := $(ROOT_DIR)/$(MODULE_NAME)
 export EXPERIMENTS_TEMPLATE := $(EXPERIMENTS_ROOT)/template.mk
+export EXPERIMENTS_VARS_TEMPLATE := $(EXPERIMENTS_ROOT)/template_vars.mk
 NUMBER_OF_SOCKETS := $(shell ls -d /sys/devices/system/node/node*/ | wc -w)
 export BOUND_MEMORY_NODE := $$(( $(NUMBER_OF_SOCKETS) - 1 ))
+export NUMBER_OF_SOCKETS := $(shell ls -d /sys/devices/system/node/node*/ | wc -w)
+export NUMBER_OF_CORES_PER_SOCKET := $(shell ls -d /sys/devices/system/node/node0/cpu*/ | wc -w)
+export EXPERIMENTS_ROOT_DIR := $(ROOT_DIR)/$(MODULE_NAME)
+export EXPERIMENTS_RUN_DIR := $(EXPERIMENTS_ROOT_DIR)/run_dir
+
+NUM_OF_REPEATS ?= $(DEFAULT_NUM_OF_REPEATS)
+NUMBER_OF_THREADS ?= $(NUMBER_OF_CORES_PER_SOCKET)
+export OMP_NUM_THREADS := $(NUMBER_OF_THREADS)
+export OMP_THREAD_LIMIT := $(OMP_NUM_THREADS) 
 
-define configuration_array
-$(addprefix configuration,$(shell seq 1 $1))
-endef
+EXPERIMENTS_WARMUP_DIR := $(EXPERIMENTS_RUN_DIR)/warmup
+WARMUP_FORCE_EXECUTION_FILE := $(EXPERIMENTS_WARMUP_DIR)/.force
 
 #### recipes and rules for prerequisites
 
-.PHONY: experiments-prerequisites perf numactl mosalloc test-run-mosalloc-tool
+.PHONY: experiments-prerequisites perf numactl mosalloc test-run-mosalloc-tool cpu_max_perf
 
 mosalloc: $(MOSALLOC_TOOL)
 $(MOSALLOC_TOOL): $(MOSALLOC_MAKEFILE)
 	$(APT_INSTALL) cmake libgtest-dev
 	cd $(dir $<)
 	cmake .
-	make -j && ctest -VV
+	if [[ $$SKIP_MOSALLOC_TEST == 0 ]]; then \
+		make -j && ctest -VV; \
+	else \
+		make -j; \
+	fi
 
 $(MOSALLOC_MAKEFILE):
 	git submodule update --init --progress
 
-experiments-prerequisites: perf numactl mosalloc
+experiments-prerequisites: perf numactl mosalloc cpu_max_perf $(PERF_COMMAND) $(WARMUP_FORCE_EXECUTION_FILE)
+
+$(WARMUP_FORCE_EXECUTION_FILE):
+	mkdir -p $(dir $@)
+	echo "Creating $@ file to force running warmup before running the first experiment"
+	touch $@
 
 PERF_PACKAGES := linux-tools
 KERNEL_VERSION := $(shell uname -r)
@@ -59,13 +94,69 @@ perf:
 	$(CHECK_PARANOID)
 	$(APT_INSTALL) "$(PERF_PACKAGES)"
 
+cpu_max_perf:
+	$(SET_CPU_MAX_PERF)
+
 numactl:
 	$(APT_INSTALL) $@
 
+$(PERF_COMMAND): $(CREATE_PERF_COMMAND)
+	$< $@
+
 TEST_RUN_MOSALLOC_TOOL := $(SCRIPTS_ROOT_DIR)/testRunMosallocTool.sh
 test-run-mosalloc-tool: $(RUN_MOSALLOC_TOOL) $(MOSALLOC_TOOL)
 	$(TEST_RUN_MOSALLOC_TOOL) $<
 
+ifdef CSET_SHIELD_RUN
+CSET_SHIELD_PREFIX=sudo -E cset shield --exec $(RUN_WITH_CONDA) --
+export SET_TASK_AFFINITY_CMD := $(CSET_SHIELD_PREFIX)
+experiments-prerequisites: cpuset
+.PHONY: cpuset
+CSET_SHIELD_CPUS := $(CSET_SHIELD_CPUS_SCRIPT) $(BOUND_MEMORY_NODE)
+cpuset:
+	$(APT_INSTALL) $@
+	$(CSET_SHIELD_CPUS)
+else
+TASKSET_PREFIX=taskset --cpu ${ISOLATED_CPUS} numactl -m ${ISOLATED_MEMORY_NODE}
+export SET_TASK_AFFINITY_CMD := $(TASKSET_PREFIX)
+check_isolation:
+	$(CHECK_ISOLATION)
+endif
+
+#### recipes and rules for creating run_and_collect_results.sh script
+
+CUSTOM_RUN_EXPERIMENT_TEMPLATE := $(EXPERIMENTS_ROOT_DIR)/run_benchmark.sh.template
+CUSTOM_RUN_EXPERIMENT_SCRIPT := $(EXPERIMENTS_ROOT_DIR)/run_benchmark.sh
+CUSTOM_COLLECT_RESULTS_TEMPLATE := $(EXPERIMENTS_ROOT_DIR)/collect_results.sh.template
+CUSTOM_COLLECT_RESULTS_SCRIPT := $(EXPERIMENTS_ROOT_DIR)/collect_results.sh
+
+RESULTS_ROOT_DIR := $(ROOT_DIR)/results
+
+$(CUSTOM_COLLECT_RESULTS_SCRIPT): | $(CUSTOM_COLLECT_RESULTS_TEMPLATE)
+	cp $| $@
+	sed -i "s,__COLLECT_RESULTS_SCRIPT__,$(COLLECT_RESULTS),g" $@
+	sed -i "s,__EXPERIMENTS_ROOT_DIR__,$(EXPERIMENTS_ROOT_DIR),g" $@
+	sed -i "s,__RESULTS_ROOT_DIR__,$(RESULTS_ROOT_DIR),g" $@
+	sed -i "s,__EXPERIMENT_NAME__,$(EXPERIMENT_NAME),g" $@
+	sed -i "s,__NUM_OF_REPEATS__,$(NUM_OF_REPEATS),g" $@
+	chmod 755 $@
+
+$(CUSTOM_RUN_EXPERIMENT_SCRIPT): $(CUSTOM_RUN_EXPERIMENT_TEMPLATE)
+	cp $< $@
+	sed -i "s,__COLLECT_RESULTS_SCRIPT__,$(COLLECT_RESULTS),g" $@
+	sed -i "s,__EXPERIMENTS_ROOT_DIR__,$(EXPERIMENTS_ROOT_DIR),g" $@
+	sed -i "s,__EXPERIMENT_NAME__,$(EXPERIMENT_NAME),g" $@
+	sed -i "s,__NUM_OF_REPEATS__,$(NUM_OF_REPEATS),g" $@
+	sed -i "s,__NUM_OF_THREADS__,$(NUMBER_OF_THREADS),g" $@
+	sed -i "s,__RUN_BENCHMARK_SCRIPT__,$(RUN_BENCHMARK),g" $@
+	sed -i "s/__RUN_BENCHMARK_PREFIX__/\"$(SET_TASK_AFFINITY_CMD)\"/g" $@
+	sed -i "s,__MEASURE_GENERAL_METRICS_SCRIPT__,$(MEASURE_GENERAL_METRICS),g" $@
+	sed -i "s,__RUN_MOSALLOC_TOOL__,$(RUN_MOSALLOC_TOOL),g" $@
+	sed -i "s,__MOSALLOC_TOOL__,$(MOSALLOC_TOOL),g" $@
+	sed -i "s,__EXTRA_ARGS_FOR_MOSALLOC__,$(EXTRA_ARGS_FOR_MOSALLOC),g" $@
+	sed -i "s,__BENCHMARK_PATH__,$(BENCHMARK_PATH),g" $@
+	chmod 755 $@
+
 #### recipes and rules for calculating the benchmark memory footprint
 
 MEMORY_FOOTPRINT_FILE := $(MODULE_NAME)/memory_footprint.csv
diff --git a/experiments/pebs_tlb_miss_trace/module.mk b/experiments/pebs_tlb_miss_trace/module.mk
index 27bbda8..1a59a7f 100644
--- a/experiments/pebs_tlb_miss_trace/module.mk
+++ b/experiments/pebs_tlb_miss_trace/module.mk
@@ -1,23 +1,30 @@
 MODULE_NAME := experiments/pebs_tlb_miss_trace
 SUBMODULES :=
 
-PERF_RECORD_FREQUENCY := $$(( 2**15 ))
+PERF_RECORD_FREQUENCY ?= $$(( 2**6 ))
 STLB_MISS_LOADS_PEBS_EVENT = $(shell perf list | grep retired | grep mem | grep stlb_miss_loads | tr -d ' ')
 STLB_MISS_STORES_PEBS_EVENT = $(shell perf list | grep retired | grep mem | grep stlb_miss_stores | tr -d ' ')
 PERF_MEM_STLB_MISSES_EVENTS = $(STLB_MISS_LOADS_PEBS_EVENT):p,$(STLB_MISS_STORES_PEBS_EVENT):p
 PERF_MEM_RECORD_CMD = perf record --data --count=$(PERF_RECORD_FREQUENCY) --event=$(PERF_MEM_STLB_MISSES_EVENTS)
 
-PEBS_EXP_OUT_DIR := $(MODULE_NAME)/repeat0
+PEBS_EXP_DIR := $(MODULE_NAME)
+PEBS_EXP_OUT_DIR := $(MODULE_NAME)/repeat1
 PEBS_TLB_MISS_TRACE_OUTPUT := $(PEBS_EXP_OUT_DIR)/perf.data
-$(PEBS_EXP_OUT_DIR): $(PEBS_TLB_MISS_TRACE_OUTPUT)
 
+$(PEBS_EXP_OUT_DIR): $(PEBS_TLB_MISS_TRACE_OUTPUT)
 $(MODULE_NAME): $(PEBS_TLB_MISS_TRACE_OUTPUT)
 
-$(PEBS_TLB_MISS_TRACE_OUTPUT): experiments/single_page_size/layouts.txt | experiments-prerequisites 
-	ARGS_FOR_MOSALLOC="$(shell grep layout4k experiments/single_page_size/layouts.txt | cut -d ':' -f 2)"
-	$(RUN_BENCHMARK) --exclude_files=$(notdir $@) \
-		--submit_command "$(PERF_MEM_RECORD_CMD) -- $(RUN_MOSALLOC_TOOL) --analyze $$ARGS_FOR_MOSALLOC --library $(MOSALLOC_TOOL)" \
-		$(BENCHMARK_PATH) $(dir $@)
+$(PEBS_TLB_MISS_TRACE_OUTPUT): experiments/single_page_size/layouts/layout4kb.csv | experiments-prerequisites 
+	$(RUN_BENCHMARK) --force \
+		--prefix="$(PERF_MEM_RECORD_CMD) --output=$(ROOT_DIR)/$@ --cpu $(ISOLATED_CPUS) $(SET_TASK_AFFINITY_CMD)" \
+		--num_threads=$(NUMBER_OF_THREADS) \
+		--num_repeats=1 \
+		--exclude_files=$(notdir $@) \
+		--submit_command \
+		"$(RUN_MOSALLOC_TOOL) --analyze -cpf $(ROOT_DIR)/experiments/single_page_size/layouts/layout4kb.csv --library $(MOSALLOC_TOOL)" \
+		--benchmark_dir=$(BENCHMARK_PATH) \
+		--output_dir=$(PEBS_EXP_DIR) \
+		--run_dir=$(EXPERIMENTS_RUN_DIR)
 
 DELETE_TARGETS := $(addsuffix /delete,$(PEBS_TLB_MISS_TRACE_OUTPUT))
 
diff --git a/experiments/random_window_2m/module.mk b/experiments/random_window_2m/module.mk
index 52ed3d4..11eab05 100644
--- a/experiments/random_window_2m/module.mk
+++ b/experiments/random_window_2m/module.mk
@@ -3,8 +3,8 @@ MODULE_NAME := experiments/random_window_2m
 include $(EXPERIMENTS_TEMPLATE)
 
 CREATE_RANDOM_WINDOW_LAYOUTS := $(MODULE_NAME)/createLayouts.py
-$(LAYOUTS_FILE): $(MEMORY_FOOTPRINT_FILE)
+$(LAYOUT_FILES): $(MEMORY_FOOTPRINT_FILE)
 	$(CREATE_RANDOM_WINDOW_LAYOUTS) \
 		--memory_footprint=$(MEMORY_FOOTPRINT_FILE) --num_layouts=$(NUM_LAYOUTS) \
-		--output=$@
+		--output=$(dir $@)/..
 
diff --git a/experiments/single_page_size/createLayouts.py b/experiments/single_page_size/createLayouts.py
index 5619f50..5c703bc 100755
--- a/experiments/single_page_size/createLayouts.py
+++ b/experiments/single_page_size/createLayouts.py
@@ -1,22 +1,17 @@
 #!/usr/bin/env python3
-
+import sys
+import os
+sys.path.append(os.path.dirname(sys.argv[0])+"/..")
+from Utils.utils import *
+from Utils.ConfigurationFile import *
 import argparse
+import math
+import os
 parser = argparse.ArgumentParser()
 parser.add_argument('-m', '--memory_footprint', default='memory_footprint.txt')
 parser.add_argument('-o', '--output', required=True)
 args = parser.parse_args()
 
-import math
-def round_up(x, base):
-    return int(base * math.ceil(x/base))
-
-def round_down(x, base):
-    return (int(x / base) * base)
-
-kb = 1024
-mb = 1024*kb
-gb = 1024*mb
-
 import pandas as pd
 footprint_df = pd.read_csv(args.memory_footprint)
 mmap_footprint = footprint_df['anon-mmap-max'][0]
@@ -24,24 +19,47 @@ brk_footprint = footprint_df['brk-max'][0]
 
 brk_pool_size = round_up(brk_footprint, 4*kb)
 mmap_pool_size = round_up(mmap_footprint, 4*kb)
+file_pool_size = 1 * gb
+
+# building configuration for layout_4kb_pages
+configuration = Configuration()
+configuration.setPoolsSize(brk_size=brk_pool_size,
+                           file_size=file_pool_size,
+                           mmap_size=mmap_pool_size)
+configuration.exportToCSV(args.output, "layout4kb")
+
+# building configuration for layout_2mb_pages
+configuration = Configuration()
+configuration.setPoolsSize(brk_size=round_up(brk_pool_size, 2*mb),
+                           file_size=file_pool_size,
+                           mmap_size=round_up(mmap_pool_size, 2*mb))
+
+configuration.addWindow(type=configuration.TYPE_MMAP,
+                        page_size=2*mb,
+                        start_offset=0,
+                        end_offset=round_up(mmap_pool_size, 2*mb))
 
-layout_remplate = '-fps 1GB -aps {0} -as1 {1} -ae1 {2} -as2 {3} -ae2 {4} -bps {5} -bs1 {6} -be1 {7} -bs2 {8} -be2 {9}'
-layout_4kb_pages = str.format(layout_remplate,
-        mmap_pool_size, 0, 0, 0, 0,
-        brk_pool_size, 0, 0, 0, 0)
-layout_2mb_pages = str.format(layout_remplate,
-        round_up(mmap_pool_size, 2*mb), 0, 0, 0, round_up(mmap_pool_size, 2*mb),
-        round_up(brk_pool_size, 2*mb), 0, 0, 0, round_up(brk_pool_size, 2*mb))
-layout_1gb_pages = str.format(layout_remplate,
-        round_up(mmap_pool_size, gb), 0, round_up(mmap_pool_size, gb),0, 0,
-        round_up(brk_pool_size, gb), 0, round_up(brk_pool_size, gb), 0, 0)
+configuration.addWindow(type=configuration.TYPE_BRK,
+                        page_size=2*mb,
+                        start_offset=0,
+                        end_offset=round_up(brk_pool_size, 2*mb))
 
-layouts = 'layout1gb: ' + layout_1gb_pages + '\n' \
-        + 'layout2mb: ' + layout_2mb_pages + '\n' \
-        + 'layout4kb: ' + layout_4kb_pages + '\n'
+configuration.exportToCSV(args.output, "layout2mb")
 
-with open(args.output, 'w+') as output_fid:
-    print(layouts, file=output_fid)
+# building configuration dor layout_1gb_pages
+configuration = Configuration()
+configuration.setPoolsSize(brk_size=round_up(brk_pool_size, 1*gb),
+                           file_size=file_pool_size,
+                           mmap_size=round_up(mmap_pool_size, 1*gb))
+configuration.addWindow(type=configuration.TYPE_MMAP,
+                        page_size=1*gb,
+                        start_offset=0,
+                        end_offset=round_up(mmap_pool_size, 1*gb))
 
+configuration.addWindow(type=configuration.TYPE_BRK,
+                        page_size=1*gb,
+                        start_offset=0,
+                        end_offset=round_up(brk_pool_size, 1*gb))
 
+configuration.exportToCSV(args.output, "layout1gb")
 
diff --git a/experiments/single_page_size/module.mk b/experiments/single_page_size/module.mk
index 7d93921..3241d7d 100644
--- a/experiments/single_page_size/module.mk
+++ b/experiments/single_page_size/module.mk
@@ -1,13 +1,22 @@
 MODULE_NAME := experiments/single_page_size
-LAYOUTS := layout2mb layout4kb
+SINGLE_PAGE_SIZE_LAYOUTS ?= layout1gb layout2mb layout4kb
+LAYOUTS := $(SINGLE_PAGE_SIZE_LAYOUTS)
+
+SINGLE_PAGE_SIZE_EXPERIMENT := $(MODULE_NAME)
 
 EXTRA_ARGS_FOR_MOSALLOC := --analyze
 
+
 include $(EXPERIMENTS_TEMPLATE)
 
 CREATE_SINGLE_PAGE_LAYOUTS := $(MODULE_NAME)/createLayouts.py
-$(LAYOUTS_FILE): $(MEMORY_FOOTPRINT_FILE)
-	$(CREATE_SINGLE_PAGE_LAYOUTS) --memory_footprint=$< --output=$@
+$(LAYOUT_FILES): $(MEMORY_FOOTPRINT_FILE)
+	$(CREATE_SINGLE_PAGE_LAYOUTS) --memory_footprint=$< \
+		--output=$(dir $@)/..
+
+
+$(MODULE_NAME)/clean:
+	rm -rf experiments/single_page_size/layouts
 
 # undefine LAYOUTS to allow next makefiles to use the defaults LAYOUTS
 undefine EXTRA_ARGS_FOR_MOSALLOC
diff --git a/experiments/sliding_window/template.mk b/experiments/sliding_window/template.mk
index 898947b..2273bba 100644
--- a/experiments/sliding_window/template.mk
+++ b/experiments/sliding_window/template.mk
@@ -2,15 +2,15 @@ MODULE_NAME := $(SLIDING_WINDOW_MODULE_NAME)/window_$(SLIDING_WINDOW_WEIGHT)
 
 include $(EXPERIMENTS_TEMPLATE)
 
-$(LAYOUTS_FILE): WEIGHT := $(SLIDING_WINDOW_WEIGHT)
-$(LAYOUTS_FILE): $(HOT_REGION_FILE) $(MEMORY_FOOTPRINT_FILE)
+$(LAYOUT_FILES): WEIGHT := $(SLIDING_WINDOW_WEIGHT)
+$(LAYOUT_FILES): $(HOT_REGION_FILE) $(MEMORY_FOOTPRINT_FILE)
 	mkdir -p $(dir $@)
 	$(CREATE_SLIDING_WINDOW_LAYOUTS) \
 		--weight=$(WEIGHT) \
 		--memory_footprint=$(MEMORY_FOOTPRINT_FILE) \
 		--hot_region=$(HOT_REGION_FILE) \
 		--num_layouts=$(NUM_LAYOUTS) \
-		--output=$@
+		--output=$(dir $@)/..
 
 $(SLIDING_WINDOW_MODULE_NAME): $(MODULE_NAME)
 $(SLIDING_WINDOW_MODULE_NAME)/clean: $(MODULE_NAME)/clean
diff --git a/experiments/template.mk b/experiments/template.mk
index 7998dc7..7c3b64d 100644
--- a/experiments/template.mk
+++ b/experiments/template.mk
@@ -1,59 +1,77 @@
-ifndef NUM_LAYOUTS
-NUM_LAYOUTS := 9
-endif # ifndef NUM_LAYOUTS
+include $(EXPERIMENTS_VARS_TEMPLATE)
 
-ifndef LAYOUTS
-LAYOUTS := $(shell seq 1 $(NUM_LAYOUTS))
-LAYOUTS := $(addprefix layout,$(LAYOUTS)) 
-endif #ifndef LAYOUTS
+define MEASUREMENTS_template =
+$(EXPERIMENT_DIR)/$(1)/$(2)/perf.out: %/perf.out: $(EXPERIMENT_DIR)/layouts/$(1).csv | experiments-prerequisites 
+	echo ========== [INFO] allocate/reserve hugepages ==========
+	$$(SET_CPU_MEMORY_AFFINITY) $$(BOUND_MEMORY_NODE) $$(RUN_MOSALLOC_TOOL) --library $$(MOSALLOC_TOOL) -cpf $$(ROOT_DIR)/$$< /bin/date
+	echo ========== [INFO] start producing: $$@ ==========
+	$$(RUN_BENCHMARK) --num_threads=$$(NUMBER_OF_THREADS) \
+		--submit_command \
+		"$$(MEASURE_GENERAL_METRICS) $$(SET_CPU_MEMORY_AFFINITY) $$(BOUND_MEMORY_NODE) \
+		$$(RUN_MOSALLOC_TOOL) --library $$(MOSALLOC_TOOL) -cpf $$(ROOT_DIR)/$$< $$(EXTRA_ARGS_FOR_MOSALLOC)" -- \
+		$$(BENCHMARK_PATH) $$*
+endef
 
-ifndef NUM_OF_REPEATS
-NUM_OF_REPEATS := 4
-endif # ifndef NUM_OF_REPEATS
+define VANILLA_template =
+$(EXPERIMENT_DIR)/$(1)/$(2)/perf.out: %/$(2)/perf.out: $(EXPERIMENT_DIR)/layouts/$(1).csv | experiments-prerequisites 
+	echo ========== [INFO] start producing: $$@ ==========
+	$$(RUN_BENCHMARK) \
+		--prefix="$$(CSET_SHIELD_PREFIX)" \
+		--num_threads=$$(NUMBER_OF_THREADS) \
+		--num_repeats=$$(NUM_OF_REPEATS) \
+		--submit_command "$$(MEASURE_GENERAL_METRICS)" \
+			-- $$(BENCHMARK_PATH) $$*
+endef
 
-EXPERIMENT_DIR := $(MODULE_NAME)
-RESULT_DIR := $(subst experiments,results,$(EXPERIMENT_DIR))
-RESULT_DIRS += $(RESULT_DIR)
-
-LAYOUTS_FILE := $(EXPERIMENT_DIR)/layouts.txt
-
-EXPERIMENTS := $(addprefix $(EXPERIMENT_DIR)/,$(LAYOUTS)) 
-RESULTS := $(addsuffix /mean.csv,$(RESULT_DIR)) 
-
-REPEATS := $(shell seq 1 $(NUM_OF_REPEATS))
-REPEATS := $(addprefix repeat,$(REPEATS)) 
-
-EXPERIMENT_REPEATS := $(foreach experiment,$(EXPERIMENTS),$(foreach repeat,$(REPEATS),$(experiment)/$(repeat)))
-MEASUREMENTS := $(addsuffix /perf.out,$(EXPERIMENT_REPEATS))
-
-$(EXPERIMENT_DIR): $(MEASUREMENTS)
-$(EXPERIMENTS): $(EXPERIMENT_DIR)/layout%: $(foreach repeat,$(REPEATS),$(addsuffix /$(repeat)/perf.out,$(EXPERIMENT_DIR)/layout%))
-$(EXPERIMENT_REPEATS): %: %/perf.out
-
-$(MEASUREMENTS): EXTRA_ARGS_FOR_MOSALLOC := $(EXTRA_ARGS_FOR_MOSALLOC)
-$(MEASUREMENTS): $(EXPERIMENT_DIR)/layout%: $(LAYOUTS_FILE) | experiments-prerequisites
-	echo ========== [INFO] start producing: $@ ==========
-	ARGS_FOR_MOSALLOC="$(shell grep layout"$(shell echo $* | cut -d '/' -f 1)" $< | cut -d ':' -f 2)"
-	if [ -z "$$ARGS_FOR_MOSALLOC" ];
-	then
-		echo "Cannot find the layout configuration to run: $@"
-		exit -1
-	fi
-	$(RUN_BENCHMARK) --submit_command "$(MEASURE_GENERAL_METRICS) $(SET_CPU_MEMORY_AFFINITY) $(BOUND_MEMORY_NODE) \
-		$(RUN_MOSALLOC_TOOL) --library $(MOSALLOC_TOOL) $$ARGS_FOR_MOSALLOC $(EXTRA_ARGS_FOR_MOSALLOC)" -- \
-		$(BENCHMARK_PATH) $(dir $@)
-
-results: $(RESULT_DIR)
-$(RESULTS): LAYOUT_LIST := $(call array_to_comma_separated,$(LAYOUTS))
-$(RESULT_DIR): $(RESULTS)
-$(RESULTS): results/%/mean.csv: experiments/%
-	mkdir -p $(dir $@)
-	$(COLLECT_RESULTS) --experiments_root=$< --repeats=$(NUM_OF_REPEATS) \
-		--layouts=$(LAYOUT_LIST) --output_dir=$(dir $@)
-
-DELETED_TARGETS := $(EXPERIMENTS) $(EXPERIMENT_REPEATS) $(LAYOUTS_FILE)
-CLEAN_TARGETS := $(addsuffix /clean,$(DELETED_TARGETS))
-$(CLEAN_TARGETS): %/clean: %/delete
-$(MODULE_NAME)/clean: $(CLEAN_TARGETS)
+define CSET_SHIELD_EXPS_template =
+$(EXPERIMENT_DIR)/$(1)/$(2)/perf.out: %/$(2)/perf.out: $(EXPERIMENT_DIR)/layouts/$(1).csv | experiments-prerequisites 
+	echo ========== [INFO] reserve hugepages before start running: $$@ ==========
+	$$(CSET_SHIELD_PREFIX) $$(RUN_MOSALLOC_TOOL) --library $$(MOSALLOC_TOOL) -cpf $$(ROOT_DIR)/$$< $$(EXTRA_ARGS_FOR_MOSALLOC) -- sleep 1
+	echo ========== [INFO] start producing: $$@ ==========
+	$$(RUN_BENCHMARK) \
+		--prefix=$$(CSET_SHIELD_PREFIX) \
+		--num_threads=$$(NUMBER_OF_THREADS) \
+		--num_repeats=$$(NUM_OF_REPEATS) \
+		--submit_command "$$(MEASURE_GENERAL_METRICS)  \
+			$$(RUN_MOSALLOC_TOOL) --library $$(MOSALLOC_TOOL) -cpf $$(ROOT_DIR)/$$< $$(EXTRA_ARGS_FOR_MOSALLOC) --debug" \
+		--benchmark_dir=$$(BENCHMARK_PATH) \
+		--output_dir=$$* \
+		--run_dir=$$(EXPERIMENTS_RUN_DIR)
+endef
 
+define TASKSET_EXPS_template =
+$(EXPERIMENT_DIR)/$(1)/$(2)/perf.out: %/$(2)/perf.out: $(EXPERIMENT_DIR)/layouts/$(1).csv | experiments-prerequisites 
+	echo ========== [INFO] reserve hugepages before start running: $$@ ==========
+	$$(TASKSET_PREFIX) $$(RUN_MOSALLOC_TOOL) --library $$(MOSALLOC_TOOL) -cpf $$(ROOT_DIR)/$$< $$(EXTRA_ARGS_FOR_MOSALLOC) -- sleep 0.1 > /dev/null 2>&1 \
+		|| $$(TASKSET_PREFIX) $$(RUN_MOSALLOC_TOOL) --library $$(MOSALLOC_TOOL) -cpf $$(ROOT_DIR)/$$< $$(EXTRA_ARGS_FOR_MOSALLOC) -- sleep 0.1
+	echo ========== [INFO] start producing: $$@ ==========
+	$$(RUN_BENCHMARK) \
+		--prefix="$$(MEASURE_GENERAL_METRICS) $$(TASKSET_PREFIX)" \
+		--num_threads=$$(NUMBER_OF_THREADS) \
+		--num_repeats=$$(NUM_OF_REPEATS) \
+		--submit_command "$$(RUN_MOSALLOC_TOOL) --library $$(MOSALLOC_TOOL) -cpf $$(ROOT_DIR)/$$< $$(EXTRA_ARGS_FOR_MOSALLOC) --debug" \
+		--benchmark_dir=$$(BENCHMARK_PATH) \
+		--output_dir=$$* \
+		--run_dir=$$(EXPERIMENTS_RUN_DIR)
+endef
 
+ifdef VANILLA_RUN
+$(foreach layout,$(LAYOUTS),$(foreach repeat,$(REPEATS),$(eval $(call VANILLA_template,$(layout),$(repeat)))))
+else 
+  ifdef SERIAL_RUN
+  $(foreach layout,$(LAYOUTS),$(foreach repeat,$(REPEATS),$(eval $(call MEASUREMENTS_template,$(layout),$(repeat)))))
+  else
+    ifdef CSET_SHIELD_RUN
+    $(foreach layout,$(LAYOUTS),$(foreach repeat,$(REPEATS),$(eval $(call CSET_SHIELD_EXPS_template,$(layout),$(repeat)))))
+    else
+      # Assert that ISOLATED_CPUS is not empty
+      ifeq ($(strip $(ISOLATED_CPUS)),)
+      $(error "===> ISOLATED_CPUS is not set! <===")
+      endif
+      ifeq ($(strip $(ISOLATED_MEMORY_NODE)),)
+      $(error "===> ISOLATED_MEMORY_NODE is not set! <===")
+      endif
+      $(foreach layout,$(LAYOUTS),$(foreach repeat,$(REPEATS),$(eval $(call TASKSET_EXPS_template,$(layout),$(repeat)))))
+    endif
+  endif
+endif
diff --git a/makefile b/makefile
index 3f27316..72ddeb6 100644
--- a/makefile
+++ b/makefile
@@ -23,7 +23,7 @@ SCRIPTS_ROOT_DIR := $(ROOT_DIR)/scripts
 
 # the following list should preserve a topological ordering, i.e., if module B
 # uses variables defined in module A, than module A should come before module B
-SUBMODULES := experiments analysis
+SUBMODULES := slurm experiments analysis
 
 include benchmark.mk
 include $(ROOT_DIR)/common.mk
diff --git a/scripts/collectMemoryFootprint.py b/scripts/collectMemoryFootprint.py
index 9a8f713..1a9b929 100755
--- a/scripts/collectMemoryFootprint.py
+++ b/scripts/collectMemoryFootprint.py
@@ -36,12 +36,12 @@ for f in allFiles:
     brk = roundToBase(brk, BASE_PAGE_SIZE)
     anon_mmap = int(max(anon_mmap+20*mb_size, anon_mmap*1.02))
     anon_mmap = roundToBase(anon_mmap, BASE_PAGE_SIZE)
-    data_frame = data_frame.append(pd.DataFrame(
-            [[brk, anon_mmap, file_mmap]], columns=df_cols))
+    pools_df = pd.DataFrame([[brk, anon_mmap, file_mmap]], columns=df_cols)
+    data_frame = pd.concat([data_frame, pools_df])
 
-regions_sum = data_frame.sum(level=0)
+regions_sum = data_frame.groupby(level=0).sum()
 regions_sum.columns = [['brk-sum', 'anon-mmap-sum', 'file-mmap-sum']]
-regions_max = data_frame.max(level=0)
+regions_max = data_frame.groupby(level=0).max()
 regions_max.columns = [['brk-max', 'anon-mmap-max', 'file-mmap-max']]
 
 out_df = regions_sum.merge(regions_max, left_index=True, right_index=True)
diff --git a/scripts/collectResults.py b/scripts/collectResults.py
index d77898e..f6a56a2 100755
--- a/scripts/collectResults.py
+++ b/scripts/collectResults.py
@@ -16,17 +16,37 @@ parser.add_argument('-l', '--layouts', required=False, default=None,
                     help='a comma-separated list of layouts')
 parser.add_argument('-r', '--repeats', default=1, type=int,
                     help='repeats number of each experiment layout')
+parser.add_argument('-d', '--remove_outliers', action='store_true',
+                    help='if specified, then layouts with outliers will be removed')
+parser.add_argument('-s', '--skip_outliers', action='store_true',
+                    help='if specified, then will skip validating outliers existance')
 parser.add_argument('-o', '--output_dir', required=True,
                     help='the directory for all output files')
 args = parser.parse_args()
 
-try:
-    layout_list = args.layouts.strip().split(',')
-except KeyError:
-    sys.exit('Error: could not parse the --layouts argument')
+if args.remove_outliers and args.skip_outliers:
+    sys.exit('Error: either --skip_outliers or --remove_outliers should be used')
 
-# build the output directory
 import os
+layout_list = []
+if args.layouts == None:
+    for f in os.scandir(args.experiments_root):
+        if f.is_dir() and f.name.startswith('layout') and not f.name == 'layouts' and not 'outlier' in f.name:
+            layout_list.append(f.name)
+    if layout_list == []:
+        print('layouts argument is empty, skipping...')
+        sys.exit(0)
+else:
+    if args.layouts.replace(' ', '') == '':
+        print('layouts argument is empty, skipping...')
+        sys.exit(0)
+
+    try:
+        layout_list = args.layouts.strip().split(',')
+    except KeyError:
+        sys.exit('Error: could not parse the --layouts argument')
+
+# build the output directory
 if not os.path.exists(args.output_dir):
     os.makedirs(args.output_dir)
 output_dir = args.output_dir + '/'
@@ -37,27 +57,46 @@ for repeat in range(1, args.repeats+1):
     experiment_list = ExperimentList(layout_list, args.experiments_root)
     df = experiment_list.collect(repeat)
     csv_file_name = 'repeat' + str(repeat) + '.csv'
-    writeDataframeToCsv(df, output_dir + csv_file_name)
+    if len(layout_list) > 1:
+        writeDataframeToCsv(df, output_dir + csv_file_name)
+    df['repeat'] = repeat
     dataframe_list.append(df)
 
-df = pd.concat(dataframe_list)
+df_with_repeats = pd.concat(dataframe_list)
+df = df_with_repeats.drop(columns=['repeat'])
 mean_df = df.groupby(df.index).mean()
+median_df = df.groupby(df.index).median()
 std_df = df.groupby(df.index).std()
 
+import datetime
 # detect outliers
 index_column = mean_df.index
 interesting_metrics = ['seconds-elapsed', 'ref-cycles', 'cpu-cycles']
 interesting_metrics = [metric for metric in interesting_metrics if metric in mean_df.columns]
 variation = std_df[interesting_metrics] / mean_df[interesting_metrics]
-outlier_threshold = 0.05
+outlier_threshold = 0.02
 outliers = variation > outlier_threshold
-if outliers.any().any():
-    print("Error: the results in", args.experiments_root, "showed considerable variation:")
-    print(outliers)
-    #sys.exit('Cells marked with True are the outliers.')
+if not args.skip_outliers:
+    if outliers.any().any():
+        print("Error: the results in", args.experiments_root, "showed considerable variation")
+        print(outliers)
+        if args.remove_outliers:
+            now = str(datetime.datetime.now())[:19]
+            now = now.replace(" ","_").replace(":","-")
+            for layout, outlier in outliers.iterrows():
+                if not outlier['seconds-elapsed'] and not outlier['cpu-cycles']:
+                    continue
+                l_old_path = args.experiments_root + '/' + layout
+                l_new_path = l_old_path + '.outlier.' + now
+                print('remove outlier: ',l_old_path,' --> ',l_new_path)
+                os.rename(l_old_path, l_new_path)
+            print('The results with outliers have been removed, please try to run them again')
+        else:
+            sys.exit('Cells marked with True are the outliers.')
 
 # if there are no outliers, write the aggregated results
-writeDataframeToCsv(df, output_dir + 'all_repeats.csv')
 writeDataframeToCsv(mean_df, output_dir + 'mean.csv')
+writeDataframeToCsv(median_df, output_dir + 'median.csv')
+writeDataframeToCsv(df_with_repeats, output_dir + 'all_repeats.csv')
 writeDataframeToCsv(std_df, output_dir + 'std.csv')
 
diff --git a/scripts/measureGeneralMetrics.sh b/scripts/measureGeneralMetrics.sh
index 6cbc258..817663b 100755
--- a/scripts/measureGeneralMetrics.sh
+++ b/scripts/measureGeneralMetrics.sh
@@ -5,39 +5,26 @@ if (( $# < 1 )); then
     exit -1
 fi
 
-command="$@"
-
-general_events="ref-cycles,cpu-cycles,instructions,"
-
-# We no longer measure the cache events because we want to reduce sampling and improve the measuring accuracy.
-#general_events+=",L1-dcache-loads,L1-dcache-stores,L1-dcache-load-misses,L1-dcache-store-misses"
-#general_events+=",LLC-loads,LLC-stores,LLC-load-misses,LLC-store-misses"
-
-prefix_perf_command="perf stat --field-separator=, --output=perf.out"
-# extract architecture specific dtlb and energy events from 'ocperf list' output
-dtlb_events=`perf list | \grep -o "dtlb_.*_misses\.\w*" | sort -u | tr '\n' ','`
-dtlb_events=${dtlb_events%?} # remove the trailing , charachter
-#dtlb_events=dtlb_load_misses.miss_causes_a_walk,dtlb_load_misses.walk_duration,dtlb_store_misses.miss_causes_a_walk,dtlb_store_misses.walk_duration
-
-# We also measure energy if the system allows it.
-energy_events=`perf list | \grep -o "\w*\/energy.*\/" | sort -u | tr '\n' ',i'`
-energy_events=${energy_events%?} # remove the trailing , charachter
+if [ -z "$MOSMODEL_RUN_OUT_DIR" ]; then
+  MOSMODEL_RUN_OUT_DIR="./"
+  echo "$0: [WARNING] - MOSMODEL_RUN_OUT_DIR variable is not set, initialize with current dir"
+fi
 
-perf_command="$prefix_perf_command --event $general_events$dtlb_events -- "
+command="$@"
 
-if [[ -z "$energy_events" ]]; then
-    echo "this CPU does not support energy events"
+# Resolve the directory of the currently executing script
+SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
+# Full path to perf_command.txt
+PERF_COMMAND_FILE="$SCRIPT_DIR/perf_command.txt"
+# Check if perf_command.txt exists
+if [ -f "$PERF_COMMAND_FILE" ]; then
+    perf_command=`eval echo $(cat ${PERF_COMMAND_FILE})`
 else
-    echo "this CPU supports energy events"
-    perf_command+="$prefix_perf_command --event $energy_events --cpu=0 -- "
+    echo " ${SCRIPT_DIR}/perf_command.txt does NOT exist."
+    exit 1  # Exit the script with a non-zero status to indicate failure
 fi
 
-time_format="seconds-elapsed,%e\nuser-time-seconds,%U\n"
-time_format+="kernel-time-seconds,%S\nmax-resident-memory-kb,%M"
-time_command="time --format=$time_format --output=time.out"
-
-submit_command="$perf_command $time_command"
 echo "Running the following command:"
-echo "$submit_command $command"
-$submit_command $command
+echo "$perf_command $command"
+$perf_command $command
 
